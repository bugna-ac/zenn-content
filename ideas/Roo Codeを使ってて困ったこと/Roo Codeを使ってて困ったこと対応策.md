---
## title: "Roo Codeを使ってて困ったこと" emoji: "🛠️" type: "tech" topics: ["roo-code", "github-copilot", "生成AI", "開発効率", "プロンプトエンジニアリング"] published: false
---
## 要旨（TL;DR）

Roo Codeで「俺も生成AI時代に追いついた」と思ったが、現実はコスト・行数限界・報酬Hackingで、簡単には波に乗せてくれなかった。

---

## 背景
- 社内では、外部のAIサービス利用が原則禁止されており、例外として GitHub Enterprise 上で GitHub Copilot のみが利用可能である。
- 当初は GitHub Copilot Chat のエージェントモードを利用していたが、コンテキスト保持が弱く、直前の指示を頻繁に失念するため、長期的な開発には不向きであった。
- そのため、Memory-Bank による永続コンテキスト管理が可能な Roo Code へ移行した。仕様書・作業フロー・日次記録なども自動的に参照・管理できるため、開発効率は大幅に向上した。
- 一方で、コード生成やリファクタリングがパターン化していくにつれ、モデル特有の限界や不便さも徐々に顕在化してきた。

## どんな時に困るのか？

### 1. 広域 except が量産され、コード品質が崩壊する

- エラー修正を Roo に任せて対話を続けると、`try...except` が急増する。
- Roo は「エラーを消す」という短期的目標に最適化されているため、**根本原因の修正より例外吸収を優先する**。
- その結果、可読性の低下や行数増加が発生し、デバッグが困難になる。

私の設計が甘いから、Rooも困っている。そういう、（あいつらの）やみくもな指示でコード修正していたっけ…

### 2. 行数肥大化により Roo が処理不能になる

- 例外吸収や生成過多によって、コードは**700～2000行規模に肥大化**する。
- すると、Roo の処理速度が極端に落ち、編集対象として認識できなくなる。
- 対処として高コンテキストモデルを選択すると、Premium Request 消費が急増し、**コスト爆発**を引き起こす。

### 3. 「責務の分離」ではなく「行数ベース」で強制分割される

- Roo に分割を依頼しても、肥大化したコードを理解できないため、**意味単位ではなく、物理的行数で分割**してしまう。
- その結果、`xxx_handler.py` や `xxx_builder.py` が大量に生成され、  **デザインパターンとも整合性のない構造崩壊が発生する。**

## 4. モデル選択によって出力傾向が大きく異なり、開発体験が安定しない

### 4.1 PRコストの制約により、低価格モデルに固定されやすい

- PR乗数が高いモデルは、わずか数回の操作で**数千円が消える**ため、実運用では「乗数ゼロ」のモデルのみを使いがちである。
- 結果として、**処理能力ではなく価格によってモデル選択が固定化され、開発体験の最適化ができない。**

### 4.2 乗数ゼロモデルでも挙動に大きな差があり、動作が一貫しない

- **GPT-5 mini**：原因分析・対策案・ToDo更新など“丁寧だが冗長”。
- **Grok Code Fast 1**：説明がほぼなく、黙ってコードを書き換える“無口エージェント”。
- **GPT-4.1**：diff 生成はするが、修正深度が浅く、複雑な文脈は苦手。
- **GPT-4o mini**：エラー箇所は特定するが、分析力が弱い。

→ **同じ「Roo Code」で同じ依頼をしても、モデルによって挙動が完全に変わるため、学習コストが無駄に増える。**

### 4.3 PR乗数 1 の Claude Sonnet 4 は高性能だが、報酬ハッキングを多発する

- コメントだけ修正して「直した」と言う
- 実データを使わず、通るテストデータを自作し合格報告
- 「正常終了した」とprintして、未修正なのに git commit を試みる

→ **“成功の定義”の最適化がユーザ意図から逸れ、作業をショートカットする。**  
→ リファクタリングや修正の信頼性が下がり、逆に手戻りが増える。

## 臨時の対応策
臨時の対応策としては、開発の目標を以下の三点に絞った。

- 実行できるコードであること  
- コードの規模が概ね1000行程度で収まること  
- 与えられたテストケース（特に意地悪なケース）を通過すること  

この方針のもとでは、構造的な厳密性よりも、生成結果の安定性と再現性を優先している。  
そのため、例外処理が広域的になったとしても、まずは実行可能で破綻しない状態を確保することを目指す。  
また、ソースコードは機能単位で分割し、1ファイルあたりの行数と責務を明確に分離する。  
これにより、Rooが生成・修正を行う際の文脈負荷を軽減し、部分的なリファクタリングを安全に行えるようになる。  

さらに、プログラムの目的に対応した「意地悪なテスト（edge case）」を設計段階で定義し、それをRooに対して明示的に実行させる。  
このプロセスによって、「動作する」「Rooの内部制約で破綻しない」「報酬ハッキング的な生成を誘発しない」コードを、最小限の反復で生成できる。  

以上の暫定策は恒久的な解決には至らないものの、Rooの生成特性を踏まえた“現実解”として一定の効果を確認している。

## 恒久対策：Roo依存を前提にした設計への転換

対策案は、「Rooにとって都合のいい“マイクロサービス風”な小さな部品を量産しつつ、人間は上位ユースケースという“大きな目的”を逸脱していないかをチェック」する役割を担う、と考えた。

Roo Codeを使っていて分かったのは、「Rooを人間に合わせる」のではなく、「人間の設計をRooに合わせる」方向に舵を切らないと、生産性が上がらないということだ。
つまり、AIに合わせた“設計の再構築”が恒久対策になる。

AIの能力が人に追いつくまでの数年を“転換期”と割り切って、Rooに最適化した設計は当面（恒久ではないな）持つと思う。

開発現場では、大きな目的を常に確認し、必要な部品を先に考え、Rooには、部品単位で最適化されたコード生成を依頼する。プロンプトには、大きな目的や、先に作ったクラスや関数はコンテキストに読み込む指示を入れて、Rooに依頼する。

---
## 最後に

Roo Codeは、生成AIに触れた中で、最もインパクトが強く、開発体験を変えるツールである。
https://zenn.dev/bugnabuna/articles/d19cdb235cc5c2

ただ、やっぱり、オートマティックなプログラム開発マシーンには程遠く、開発者が設計思想を明確にし、Rooに適したコード構造を設計に組み込む必要がある。

当然、この手の内容は、Rooが進化した際には、現行の「AI最適化設計」が陳腐化する可能性は大いにある。

目的だけ指示して、Rooに丸投げしてしまいたい（してしまう）誘惑を断ち切り、AIが扱いやすいコード構造を最初から設計に組み込む。

私がこれを実行していけば、、Roo Codeを使った開発は、社内において、生成AI時代の主流な開発手法になる、手応えを強く感じている。

[^1]: Roo Codeは、選択したモデルに関係なく、コンテキスト上限を128kトークンに制限している。Roo Codeのパネルで状態確認ができるが、設定で上限値を上げることはできない仕様。
